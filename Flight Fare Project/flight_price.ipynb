{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd8900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f90f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(r\"D:\\Project\\Data_Train_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278b6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8b987f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>Janakpur</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>JKR → KTM</td>\n",
       "      <td>10:56:00</td>\n",
       "      <td>19:16:00</td>\n",
       "      <td>30m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>4670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>Yeti</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>KTM → BRT</td>\n",
       "      <td>10:57:00</td>\n",
       "      <td>19:17:00</td>\n",
       "      <td>45m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No Info</td>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>Shree</td>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Simara</td>\n",
       "      <td>KTM → SIF</td>\n",
       "      <td>10:58:00</td>\n",
       "      <td>19:18:00</td>\n",
       "      <td>20m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>PKR → KTM</td>\n",
       "      <td>10:59:00</td>\n",
       "      <td>19:19:00</td>\n",
       "      <td>25m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>BIR → KTM</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Airline Date_of_Journey      Source Destination      Route  Dep_Time  \\\n",
       "10683  Buddha      2023-06-23    Janakpur   Kathmandu  JKR → KTM  10:56:00   \n",
       "10684    Yeti      2023-05-01   Kathmandu  Biratnagar  KTM → BRT  10:57:00   \n",
       "10685   Shree      2023-04-21   Kathmandu      Simara  KTM → SIF  10:58:00   \n",
       "10686  Buddha      2023-08-21     Pokhara   Kathmandu  PKR → KTM  10:59:00   \n",
       "10687  Buddha      2023-05-25  Biratnagar   Kathmandu  BIR → KTM  11:00:00   \n",
       "\n",
       "      Arrival_Time Duration Total_Stops               Additional_Info  Price  \n",
       "10683     19:16:00      30m    non-stop  No check-in baggage included   4670  \n",
       "10684     19:17:00      45m    non-stop                       No Info   5500  \n",
       "10685     19:18:00      20m    non-stop  No check-in baggage included   3660  \n",
       "10686     19:19:00      25m    non-stop  No check-in baggage included   4200  \n",
       "10687     19:20:00      40m    non-stop  No check-in baggage included   5625  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bfa5f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10688 entries, 0 to 10687\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Airline          10688 non-null  object        \n",
      " 1   Date_of_Journey  10688 non-null  datetime64[ns]\n",
      " 2   Source           10688 non-null  object        \n",
      " 3   Destination      10688 non-null  object        \n",
      " 4   Route            10687 non-null  object        \n",
      " 5   Dep_Time         10688 non-null  object        \n",
      " 6   Arrival_Time     10688 non-null  object        \n",
      " 7   Duration         10688 non-null  object        \n",
      " 8   Total_Stops      10687 non-null  object        \n",
      " 9   Additional_Info  10688 non-null  object        \n",
      " 10  Price            10688 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(9)\n",
      "memory usage: 918.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51631e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2h 50m     550\n",
       "1h 30m     386\n",
       "2h 55m     337\n",
       "2h 45m     337\n",
       "2h 35m     329\n",
       "          ... \n",
       "30h 10m      1\n",
       "31h 30m      1\n",
       "42h 5m       1\n",
       "4h 10m       1\n",
       "40m          1\n",
       "Name: Duration, Length: 373, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcbed7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d315d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              0\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        0\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422950e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Journey_day\"] = pd.to_datetime(train_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7038a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Journey_month\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888598a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>Janakpur</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>JKR → KTM</td>\n",
       "      <td>10:56:00</td>\n",
       "      <td>19:16:00</td>\n",
       "      <td>30m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>4670</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>Yeti</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>KTM → BRT</td>\n",
       "      <td>10:57:00</td>\n",
       "      <td>19:17:00</td>\n",
       "      <td>45m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No Info</td>\n",
       "      <td>5500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>Shree</td>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Simara</td>\n",
       "      <td>KTM → SIF</td>\n",
       "      <td>10:58:00</td>\n",
       "      <td>19:18:00</td>\n",
       "      <td>20m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>3660</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>PKR → KTM</td>\n",
       "      <td>10:59:00</td>\n",
       "      <td>19:19:00</td>\n",
       "      <td>25m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>4200</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>Buddha</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>BIR → KTM</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>5625</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Airline Date_of_Journey      Source Destination      Route  Dep_Time  \\\n",
       "10683  Buddha      2023-06-23    Janakpur   Kathmandu  JKR → KTM  10:56:00   \n",
       "10684    Yeti      2023-05-01   Kathmandu  Biratnagar  KTM → BRT  10:57:00   \n",
       "10685   Shree      2023-04-21   Kathmandu      Simara  KTM → SIF  10:58:00   \n",
       "10686  Buddha      2023-08-21     Pokhara   Kathmandu  PKR → KTM  10:59:00   \n",
       "10687  Buddha      2023-05-25  Biratnagar   Kathmandu  BIR → KTM  11:00:00   \n",
       "\n",
       "      Arrival_Time Duration Total_Stops               Additional_Info  Price  \\\n",
       "10683     19:16:00      30m    non-stop  No check-in baggage included   4670   \n",
       "10684     19:17:00      45m    non-stop                       No Info   5500   \n",
       "10685     19:18:00      20m    non-stop  No check-in baggage included   3660   \n",
       "10686     19:19:00      25m    non-stop  No check-in baggage included   4200   \n",
       "10687     19:20:00      40m    non-stop  No check-in baggage included   5625   \n",
       "\n",
       "       Journey_day  Journey_month  \n",
       "10683           23              6  \n",
       "10684            1              5  \n",
       "10685           21              4  \n",
       "10686           21              8  \n",
       "10687           25              5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "940ea468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have converted Date_of_Journey column into integers, Now we can drop as it is of no use.\n",
    "\n",
    "train_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1a4dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'datetime.time'> is not convertible to datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Departure time is when a plane leaves the gate. \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Similar to Date_of_Journey we can extract values from Dep_Time\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extracting Hours\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDep_hour\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDep_Time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extracting Minutes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDep_min\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDep_Time\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mminute\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1064\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1062\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(tz)\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1064\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:229\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    227\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 229\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:833\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:655\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'datetime.time'> is not convertible to datetime"
     ]
    }
   ],
   "source": [
    "# Departure time is when a plane leaves the gate. \n",
    "# Similar to Date_of_Journey we can extract values from Dep_Time\n",
    "\n",
    "# Extracting Hours\n",
    "train_data[\"Dep_hour\"] = pd.to_datetime(train_data[\"Dep_Time\"]).dt.hour\n",
    "\n",
    "# Extracting Minutes\n",
    "train_data[\"Dep_min\"] = pd.to_datetime(train_data[\"Dep_Time\"]).dt.minute\n",
    "\n",
    "# Now we can drop Dep_Time as it is of no use\n",
    "train_data.drop([\"Dep_Time\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0444287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32199e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrival time is when the plane pulls up to the gate.\n",
    "# Similar to Date_of_Journey we can extract values from Arrival_Time\n",
    "\n",
    "# Extracting Hours\n",
    "train_data[\"Arrival_hour\"] = pd.to_datetime(train_data.Arrival_Time).dt.hour\n",
    "\n",
    "# Extracting Minutes\n",
    "train_data[\"Arrival_min\"] = pd.to_datetime(train_data.Arrival_Time).dt.minute\n",
    "\n",
    "# Now we can drop Arrival_Time as it is of no use\n",
    "train_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24465e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time taken by plane to reach destination is called Duration\n",
    "# It is the differnce betwwen Departure Time and Arrival time\n",
    "\n",
    "\n",
    "# Assigning and converting Duration column into list\n",
    "duration = list(train_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1863b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding duration_hours and duration_mins list to train_data dataframe\n",
    "\n",
    "train_data[\"Duration_hours\"] = duration_hours\n",
    "train_data[\"Duration_mins\"] = duration_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data.drop([\"Duration\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Airline\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From graph we can see that Jet Airways Business have the highest Price.\n",
    "# Apart from the first Airline almost all are having similar median\n",
    "\n",
    "# Airline vs Price\n",
    "sns.catplot(y = \"Price\", x = \"Airline\", data = train_data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd17291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Airline is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Airline = train_data[[\"Airline\"]]\n",
    "\n",
    "Airline = pd.get_dummies(Airline, drop_first= True)\n",
    "\n",
    "Airline.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source vs Price\n",
    "\n",
    "sns.catplot(y = \"Price\", x = \"Source\", data = train_data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb092e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Source is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Source = train_data[[\"Source\"]]\n",
    "\n",
    "Source = pd.get_dummies(Source, drop_first= True)\n",
    "\n",
    "Source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data[\"Destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Destination is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Destination = train_data[[\"Destination\"]]\n",
    "\n",
    "Destination = pd.get_dummies(Destination, drop_first = True)\n",
    "\n",
    "Destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256872f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Route\"]\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c087c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional_Info contains almost 80% no_info\n",
    "# Route and Total_Stops are related to each other\n",
    "\n",
    "train_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd17a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Total_Stops\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is case of Ordinal Categorical type we perform LabelEncoder\n",
    "# Here Values are assigned with corresponding keys\n",
    "\n",
    "train_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframe --> train_data + Airline + Source + Destination\n",
    "\n",
    "data_train = pd.concat([train_data, Airline, Source, Destination], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff25755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d10fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(r\"D:\\Project\\Test_set.xlsx\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a421ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "print(\"Test data Info\")\n",
    "print(\"-\"*75)\n",
    "print(test_data.info())\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Null values :\")\n",
    "print(\"-\"*75)\n",
    "test_data.dropna(inplace = True)\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# EDA\n",
    "\n",
    "# Date_of_Journey\n",
    "test_data[\"Journey_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n",
    "test_data[\"Journey_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month\n",
    "test_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n",
    "\n",
    "# Dep_Time\n",
    "test_data[\"Dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\n",
    "test_data[\"Dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\n",
    "test_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Arrival_Time\n",
    "test_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\n",
    "test_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\n",
    "test_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Duration\n",
    "duration = list(test_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n",
    "\n",
    "# Adding Duration column to test set\n",
    "test_data[\"Duration_hours\"] = duration_hours\n",
    "test_data[\"Duration_mins\"] = duration_mins\n",
    "test_data.drop([\"Duration\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Categorical data\n",
    "\n",
    "print(\"Airline\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Airline\"].value_counts())\n",
    "Airline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Source\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Source\"].value_counts())\n",
    "Source = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Destination\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Destination\"].value_counts())\n",
    "Destination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)\n",
    "\n",
    "# Additional_Info contains almost 80% no_info\n",
    "# Route and Total_Stops are related to each other\n",
    "test_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n",
    "\n",
    "# Replacing Total_Stops\n",
    "test_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n",
    "\n",
    "# Concatenate dataframe --> test_data + Airline + Source + Destination\n",
    "test_data = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n",
    "\n",
    "test_data.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Shape of test data : \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab557b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fdd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data_train.loc[:, ['Total_Stops', 'Journey_day', 'Journey_month', 'Dep_hour',\n",
    "       'Dep_min', 'Arrival_hour', 'Arrival_min', 'Duration_hours',\n",
    "       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
    "       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
    "       'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n",
    "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
    "       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n",
    "       'Destination_Kolkata', 'Destination_New Delhi']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_train.iloc[:, 1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds correlation between Independent and dependent attributes\n",
    "\n",
    "plt.figure(figsize = (18,18))\n",
    "sns.heatmap(train_data.corr(), annot = True, cmap = \"RdYlGn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ac85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds correlation between Independent and dependent attributes\n",
    "\n",
    "plt.figure(figsize = (18,18))\n",
    "sns.heatmap(train_data.corr(), annot = True, cmap = \"RdYlGn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important feature using ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "selection = ExtraTreesRegressor()\n",
    "selection.fit(X, y)\n",
    "print(selection.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10454a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f17d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aafa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3575243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c80424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE/(max(DV)-min(DV))\n",
    "\n",
    "2090.5509/(max(y)-min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db780c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE/(max(DV)-min(DV))\n",
    "\n",
    "2090.5509/(max(y)-min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper paramater tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5aec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef489d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2421576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be64335",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 700,\n",
    " 'min_samples_split': 15,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.distplot(y_test-prediction)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test, prediction, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a20993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8840e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file =open(\"flight_rf.pkl\",\"wb\")\n",
    "pickle.dump(reg_rf,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2b543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2df1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54950256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b71e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c0ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
